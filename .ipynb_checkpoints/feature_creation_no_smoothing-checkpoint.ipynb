{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from creation_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       UnixTime  e2v03  no2  Temp    Rh\n",
      "date                                                   \n",
      "2014-07-17 17:55:52  1405619752    608  874  36.2  23.3\n",
      "2014-07-17 17:55:57  1405619757    608  874  36.1  23.3\n",
      "2014-07-17 17:56:02  1405619762    608  873  36.2  23.3\n",
      "2014-07-17 17:56:06  1405619766    608  873  36.2  23.2\n",
      "2014-07-17 17:56:11  1405619771    608  873  36.2  23.2\n"
     ]
    }
   ],
   "source": [
    "df_P = pd.io.parsers.read_csv(filepath_or_buffer = 'data/cham3_coll.csv',index_col = 0)\n",
    "print df_P[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     e2v03  no2  Temp    Rh\n",
      "date                                       \n",
      "2014-07-17 17:55:52    608  874  36.2  23.3\n",
      "2014-07-17 17:55:57    608  874  36.1  23.3\n",
      "2014-07-17 17:56:02    608  873  36.2  23.3\n",
      "2014-07-17 17:56:06    608  873  36.2  23.2\n",
      "2014-07-17 17:56:11    608  873  36.2  23.2\n"
     ]
    }
   ],
   "source": [
    "df_P.drop(df_P.columns[0], axis=1, inplace=True)\n",
    "print df_P.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make log, slope, and integral terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e2v03', 'ln_O3', 'Temp', 'ln_temp', 'Rh', 'ln_rh']\n"
     ]
    }
   ],
   "source": [
    "#log terms\n",
    "df_P['ln_O3'] = np.log(df_P['e2v03'])\n",
    "df_P['ln_temp'] =np.log(df_P['Temp'])\n",
    "df_P['ln_rh'] = np.log(df_P['Rh'])\n",
    "\n",
    "feature_list = ['e2v03', 'ln_O3', 'Temp', 'ln_temp', 'Rh', 'ln_rh']\n",
    "print feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "['e2v03', 'no2', 'Temp', 'Rh', 'ln_O3', 'ln_temp', 'ln_rh', 'e2v03_int_lag_1', 'e2v03_int_lag_3', 'e2v03_int_lag_5', 'e2v03_int_lead_1', 'e2v03_int_lead_3', 'e2v03_int_lead_5', 'diff', 'e2v03_slope_lag_1', 'e2v03_slope_lag_3', 'e2v03_slope_lag_5', 'e2v03_slope_lead_1', 'e2v03_slope_lead_3', 'e2v03_slope_lead_5', 'ln_O3_int_lag_1', 'ln_O3_int_lag_3', 'ln_O3_int_lag_5', 'ln_O3_int_lead_1', 'ln_O3_int_lead_3', 'ln_O3_int_lead_5', 'ln_O3_slope_lag_1', 'ln_O3_slope_lag_3', 'ln_O3_slope_lag_5', 'ln_O3_slope_lead_1', 'ln_O3_slope_lead_3', 'ln_O3_slope_lead_5', 'Temp_int_lag_1', 'Temp_int_lag_3', 'Temp_int_lag_5', 'Temp_int_lead_1', 'Temp_int_lead_3', 'Temp_int_lead_5', 'Temp_slope_lag_1', 'Temp_slope_lag_3', 'Temp_slope_lag_5', 'Temp_slope_lead_1', 'Temp_slope_lead_3', 'Temp_slope_lead_5', 'ln_temp_int_lag_1', 'ln_temp_int_lag_3', 'ln_temp_int_lag_5', 'ln_temp_int_lead_1', 'ln_temp_int_lead_3', 'ln_temp_int_lead_5', 'ln_temp_slope_lag_1', 'ln_temp_slope_lag_3', 'ln_temp_slope_lag_5', 'ln_temp_slope_lead_1', 'ln_temp_slope_lead_3', 'ln_temp_slope_lead_5', 'Rh_int_lag_1', 'Rh_int_lag_3', 'Rh_int_lag_5', 'Rh_int_lead_1', 'Rh_int_lead_3', 'Rh_int_lead_5', 'Rh_slope_lag_1', 'Rh_slope_lag_3', 'Rh_slope_lag_5', 'Rh_slope_lead_1', 'Rh_slope_lead_3', 'Rh_slope_lead_5', 'ln_rh_int_lag_1', 'ln_rh_int_lag_3', 'ln_rh_int_lag_5', 'ln_rh_int_lead_1', 'ln_rh_int_lead_3', 'ln_rh_int_lead_5', 'ln_rh_slope_lag_1', 'ln_rh_slope_lag_3', 'ln_rh_slope_lag_5', 'ln_rh_slope_lead_1', 'ln_rh_slope_lead_3', 'ln_rh_slope_lead_5']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(feature_list)):\n",
    "    print i\n",
    "    df_P = make_func_caller_find_lag_integral(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lead_integral(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lag_slope(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lead_slope(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lag_integral(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lead_integral(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lag_slope(df_P, 1, 5, 2, feature_list[i])\n",
    "    df_P = make_func_caller_find_lead_slope(df_P, 1, 5, 2, feature_list[i])\n",
    "\n",
    "features = list(df_P.columns)\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77884, 80)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Delete the first and last 90 rows of the dataframe to remove all NaNs.\n",
    "df_P = df_P.ix[10:len(df_P['e2v03'])-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make polynomial and interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_P[feature_list].values\n",
    "poly = PolynomialFeatures(2)\n",
    "features = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See which features are combined by poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.powers_[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "i_count = 0\n",
    "for i in range(0,len(poly.powers_)):\n",
    "    if np.sum(poly.powers_[i]) > 1:\n",
    "        for j in range(0,len(feature_list)):\n",
    "            if poly.powers_[i,j] == 2:\n",
    "                name.append(feature_list[j] + '_sq')\n",
    "            if poly.powers_[i,j] == 1:\n",
    "                i_count += 1\n",
    "                if i_count == 1:\n",
    "                    name1 = feature_list[j]\n",
    "                elif i_count == 2:\n",
    "                    name.append(name1 + '_interact_' +feature_list[j])\n",
    "                    i_count = 0\n",
    "    else: \n",
    "        name.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 'e2v03_sq',\n",
       " 'e2v03_interact_ln_O3',\n",
       " 'e2v03_interact_Temp',\n",
       " 'e2v03_interact_ln_temp',\n",
       " 'e2v03_interact_Rh',\n",
       " 'e2v03_interact_ln_rh',\n",
       " 'ln_O3_sq',\n",
       " 'ln_O3_interact_Temp',\n",
       " 'ln_O3_interact_ln_temp',\n",
       " 'ln_O3_interact_Rh',\n",
       " 'ln_O3_interact_ln_rh',\n",
       " 'Temp_sq',\n",
       " 'Temp_interact_ln_temp',\n",
       " 'Temp_interact_Rh',\n",
       " 'Temp_interact_ln_rh',\n",
       " 'ln_temp_sq',\n",
       " 'ln_temp_interact_Rh',\n",
       " 'ln_temp_interact_ln_rh',\n",
       " 'Rh_sq',\n",
       " 'Rh_interact_ln_rh',\n",
       " 'ln_rh_sq']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P['ref_o3_smooth'].plot(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P.to_csv(path_or_buf = '7_25_closed_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
